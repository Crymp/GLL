{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1707ea395e714b218ab4f7ebbe308b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'selector': 'node', 'css': {'background-c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import ipycytoscape\n",
    "import networkx as nx\n",
    "\n",
    "def vis(G):\n",
    "    cso = ipycytoscape.CytoscapeWidget()\n",
    "    cso.graph.add_graph_from_networkx(G)\n",
    "    cso.set_style([\n",
    "                            {\n",
    "                                'selector': 'node',\n",
    "                                'css': {\n",
    "                                    'background-color': 'red',\n",
    "                                    'content': 'data(node_label)' #\n",
    "                                }\n",
    "                            },\n",
    "                                                    {\n",
    "                                'selector': 'edge',\n",
    "                                'css': {\n",
    "                                    'content': 'data(edge_label)' #\n",
    "                                }\n",
    "                            }\n",
    "                \n",
    "                ])\n",
    "\n",
    "    for i in range(len(cso.graph.nodes)):\n",
    "        id = int(cso.graph.nodes[i].data['id'])\n",
    "        label = cso.graph.nodes[i].data['node_label']\n",
    "        new_label = f\"{id}: {label}\"\n",
    "        cso.graph.nodes[i].data['node_label'] = new_label\n",
    "\n",
    "\n",
    "    # for i in range(len(cso.graph.edges)):\n",
    "    #     label = cso.graph.edges[i].data['edge_label']\n",
    "    #     new_label = f\"{label}\"\n",
    "    #     cso.graph.edges[i].data['edge_label'] = new_label\n",
    "\n",
    "    return cso\n",
    "    \n",
    "# Test it with output graph\n",
    "import pickle\n",
    "#with open('datasets/DD/data.pkl','rb') as f:\n",
    "with open('../datasets/ZINC_TEST/data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "out = vis(data[3])\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcae1a5b33a4682a11aaf6259a6ce35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'selector': 'node', 'css': {'background-c…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class SparseGraph:\n",
    "    # Convert a graph to a sparse representation (numpy matrices)\n",
    "    def __init__(self, G):\n",
    "        # Convert a networkx graph (with edge and node labels) to a sparse graph format\n",
    "\n",
    "        # Edge index Matrix\n",
    "        idxs = np.array(G.edges).transpose() # (2,|E|) dim. array idxs[:,j] = [u,v]^T indicates endpoints of j'th edge e=u->v\n",
    "        idxs = np.concatenate((idxs, idxs[[1,0]]), axis=1) # idxs[[1,0]] flips the two rows ie [u,v]^T -> [v,u]^T, so by concat now have (2, 2*|E|)\n",
    "        self.idxs = torch.from_numpy(idxs) #.astype(np.float32))\n",
    "\n",
    "        # Node features\n",
    "        Xv = np.array([G.nodes[idx]['node_label'] for idx in G.nodes]).transpose()#.reshape(-1,1) # Node feature matrix of dim (reshape: (|V|,) -> (|V|,1))\n",
    "        self.Xv = torch.from_numpy(Xv.astype(np.float32))\n",
    "        \n",
    "        # Edges features\n",
    "        Xe = np.array([G.edges[idx]['edge_label'] for idx in G.edges]).transpose()#.reshape(-1,1) # Edge feature matrix of dim (reshape: (|E|,) -> (|E|,1))\n",
    "        Xe = np.concatenate((Xe,Xe), axis=0)\n",
    "        self.Xe = torch.from_numpy(Xe.astype(np.float32))\n",
    "\n",
    "        # Get Graph features\n",
    "        y = G.graph['label']\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    def to_nx(self):\n",
    "        # Convert the sparse graph back to a networkx gaph g\n",
    "\n",
    "        # Convert tensors to numpy\n",
    "        idxs = self.idxs.numpy().astype('int')\n",
    "        Xv = self.Xv.numpy()\n",
    "        Xe = self.Xe.numpy()\n",
    "\n",
    "        g = nx.Graph() # Empty nx graph\n",
    "\n",
    "        # Add edges (nodes added automatically)\n",
    "        for j in range(idxs.shape[1]):\n",
    "            g.add_edge(idxs[0,j], idxs[1,j])\n",
    "        \n",
    "        # Set Node and Edge Weights\n",
    "        nx.set_node_attributes(g, {idx: Xv[idx] for idx in range(Xv.shape[0])}, \"node_label\")\n",
    "        nx.set_edge_attributes(g, {(idxs[0,idx], idxs[1,idx]): Xe[idx] for idx in range(int(Xe.shape[0]/2))}, \"edge_label\")\n",
    "\n",
    "        # TODO: Convert graph label in networkx\n",
    "        return g\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, nx_graph_list):\n",
    "        self.np_sparse_graphs = [SparseGraph(g) for g in nx_graph_list]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.np_sparse_graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.np_sparse_graphs[idx]\n",
    "        #return torch.from_numpy(sg.idxs), torch.from_numpy(sg.Xv), torch.from_numpy(sg.Xe), torch.from_numpy(sg.Xe)\n",
    "\n",
    "\n",
    "SG = SparseGraph(data[3])\n",
    "G1 = SG.to_nx()\n",
    "vis(G1)\n",
    "\n",
    "def MyCollate(sparse_graph_list):\n",
    "    #sparse_graph_list = [SparseGraph(data[0]), SparseGraph(data[1]), SparseGraph(data[2]) ]\n",
    "    #sgl = sparse_graph_list\n",
    "\n",
    "    # Create empty SparseGraph Object (avoid calling init, we will initialize here alreadt)\n",
    "    output = SparseGraph.__new__(SparseGraph)\n",
    "\n",
    "    # By joining graphs, the node indexes need to she shifted\n",
    "    # Ie if the first graph has 10 nodes, then for the second graph the node indexes 0,1,2,... --> 10,11,12,...\n",
    "\n",
    "    # compute batch_idx matrix, and a lookup table for how much to shift each graph's nodes indexes by\n",
    "    node_idx_shift = [0] # Lookup table for the node index shift of each graph\n",
    "    output.batch_idx = []\n",
    "    tot_num_nodes = 0 # Total number of nodes\n",
    "    for i,sg in enumerate(sparse_graph_list):\n",
    "        num_nodes = sg.Xv.shape[0]\n",
    "        tot_num_nodes += num_nodes\n",
    "        node_idx_shift.append(tot_num_nodes)\n",
    "        output.batch_idx += [i]*num_nodes\n",
    "\n",
    "    # First shift all the node indexes in each graph, and concatenate them\n",
    "    output.idxs = torch.cat([sg.idxs + torch.from_numpy(np.array([node_idx_shift[i], node_idx_shift[i]]).transpose().reshape(-1,1))  # idxs + [idx_shift, idx_shift]^T\n",
    "                            for i, sg in enumerate(sparse_graph_list)],\n",
    "                        dim = 1)\n",
    "\n",
    "    # Concatenate Node and Edge feature vectors, and graph labels\n",
    "    output.Xv = torch.cat([sg.Xv  for sg in sparse_graph_list])\n",
    "    output.Xe = torch.cat([sg.Xe for sg in sparse_graph_list])\n",
    "    output.y = torch.cat([sg.y for sg in sparse_graph_list])\n",
    "\n",
    "    return output\n",
    "\n",
    "sgl = [SparseGraph(data[0]), SparseGraph(data[1])] #SparseGraph(data[2]) ]\n",
    "res = MyCollate(sgl)\n",
    "vis(res.to_nx())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch import nn\n",
    "class SLP(torch.nn.Module):\n",
    "    # Single Layer Perceptron (Dummy Function)\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SLP, self).__init__()\n",
    "        self.fc = nn.Linear( in_features, out_features)\n",
    "        self.relu = torch.nn.ReLU() # instead of Heaviside step fn\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x) # instead of Heaviside step fn\n",
    "        return x\n",
    "\n",
    "\n",
    "U = SLP(2,1)\n",
    "x = torch.tensor(np.array([1,1]), dtype=torch.float32) #.reshape(-1,1),\n",
    "U.forward(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5328],\n",
      "        [0.1632],\n",
      "        [0.2072]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0.5328], grad_fn=<ReluBackward0>),\n",
       " tensor([0.1632], grad_fn=<ReluBackward0>),\n",
       " tensor([0.2072], grad_fn=<ReluBackward0>)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sanity Check ahhh\n",
    "M = SLP(2,1)\n",
    "\n",
    "X = torch.tensor(np.array([[1,-2],[2,0],[3,-2]]), dtype=torch.float32)\n",
    "X = torch.transpose(X,0,1) # Shape (2,3)\n",
    "\n",
    "\n",
    "foo = M.forward(torch.transpose(X,0,1))\n",
    "# foo shape (1,3)\n",
    "print(foo)\n",
    "\n",
    "[M.forward(X[:,0]), M.forward(X[:,1]), M.forward(X[:,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = SLP(2,2)\n",
    "U = SLP(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MORE SANITY Checks\n",
    "\n",
    "import torch_scatter\n",
    "\n",
    "sg = sgl[0]\n",
    "num_nodes = sg.Xv.shape[0]\n",
    "Xe = sg.Xe\n",
    "Xe = Xe.reshape((-1,1))\n",
    "Xe.shape # (34, 1)\n",
    "\n",
    "H = torch.ones((num_nodes))\n",
    "H = H.reshape((-1,1))\n",
    "H.shape # (16,1)\n",
    "\n",
    "idxs = sg.idxs\n",
    "idxs.shape # (2, 34)\n",
    "\n",
    "H_Xe = torch.cat((H[idxs[0,:]], Xe), dim=1)\n",
    "H_Xe.shape # (34,2) = (2|E|, Xe.shape[1] + H.shape[1])\n",
    "\n",
    "Y = M.forward(H_Xe)\n",
    "Y.shape # (34,1) = (2|E|, 1)\n",
    "\n",
    "Z = torch_scatter.scatter_add(Y, idxs[1,:], dim=0)\n",
    "Z.shape # (16, 1) = (|V|, 1)\n",
    "\n",
    "H_Z = torch.cat((H,Z), dim=1)\n",
    "H_Z.shape # (16,2) = (|V|, H)\n",
    "\n",
    "H_new = U.forward(H_Z)\n",
    "H_new.shape # (16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = H.reshape((-1,1))\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MORE SANITY Checks\n",
    "\n",
    "# import torch_scatter\n",
    "\n",
    "# sg = sgl[0]\n",
    "# num_nodes = sg.Xv.shape[0]\n",
    "# Xe = sg.Xe\n",
    "# H = torch.ones((num_nodes))\n",
    "# H = H.reshape((-1,1))\n",
    "# idxs = sg.idxs\n",
    "\n",
    "\n",
    "# H_hat = H[idxs[0,:]]\n",
    "# H_Xe = torch.stack((H[idxs[0,:]], Xe)) \n",
    "# H_Xe.shape # (2,34)\n",
    "\n",
    "# Y = M.forward(torch.transpose(H_Xe,0,1))\n",
    "# Y.shape # (34,1)\n",
    "# #Y = torch.transpose(Y,0,1)\n",
    "\n",
    "# Z = torch_scatter.scatter_add(Y, idxs[1,:], dim=0)\n",
    "# Z.shape # (16, 1)\n",
    "\n",
    "# # Z = Z.reshape((-1)) \n",
    "# # Z.shape # (16)\n",
    "\n",
    "# H_Z = torch.stack((H, Z))\n",
    "# H_Z.shape # (2,16)\n",
    "\n",
    "# H_Z = torch.transpose(H_Z,1,0)\n",
    "# H_Z.shape #(16,2)\n",
    "\n",
    "# H_new = U.forward(H_Z)\n",
    "# H_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "class GNN_U(torch.nn.Module):\n",
    "    # TODO: Actually implement this! Just dummy so far (see depth attribute)\n",
    "\n",
    "    def __init__(self, in_features, out_features, depth):\n",
    "        super(GNN_U, self).__init__()\n",
    "        self.fc = nn.Linear( in_features, out_features)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x) \n",
    "        return x\n",
    "\n",
    "class GNN_M(torch.nn.Module):\n",
    "    # TODO: Actually implement this! Just dummy so far (see depth attribute)\n",
    "    def __init__(self, in_features, out_features, depth):\n",
    "        super(GNN_M, self).__init__()\n",
    "        self.fc = nn.Linear( in_features, out_features)\n",
    "        self.relu = torch.nn.ReLU() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x) \n",
    "        return x\n",
    "\n",
    "\n",
    "class GNN_layer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, Xe_width, scatter_func='SUM', U_depth=2, M_depth=2, M_width=2):\n",
    "        super(GNN_layer, self).__init__()\n",
    "\n",
    "        # Initialize Scatter function\n",
    "        if type(scatter_func) == type('str'):\n",
    "            import torch_scatter\n",
    "            if scatter_func.lower()=='sum':\n",
    "                self.scatter_agg = torch_scatter.scatter_add\n",
    "            elif scatter_func.lower()=='max':\n",
    "                self.scatter_agg = torch_scatter.scatter_max\n",
    "            elif scatter_func.lower()=='mean':\n",
    "                self.scatter_agg = torch_scatter.scatter_mean\n",
    "            else:\n",
    "                import warnings\n",
    "                warnings.warn(\"scatter_function unknown! Defaulting to \\\"SUM\\\"\")\n",
    "                self.scatter_agg = torch_scatter.scatter_add\n",
    "        else: \n",
    "            # Custom scatter function\n",
    "            self.scatter_agg = scatter_func\n",
    "\n",
    "        # Initialize M and U Neural Nets\n",
    "        self.M = GNN_M(in_features + Xe_width, M_width, M_depth)\n",
    "        self.U = GNN_U(in_features + M_width, out_features, U_depth)\n",
    "\n",
    "    def forward(self, H, sparse_graph):\n",
    "        foo = torch.cat((H[sparse_graph.idxs[0,:]], sparse_graph.Xe), dim=1)\n",
    "        Y = self.M.forward(foo)\n",
    "        #Y = M.forward(torch.cat((H[sparse_graph.idxs[0,:]], sparse_graph.Xe), dim=1)) # (2|E|, in_features + Xe_width) -> (2|E|, M_width)\n",
    "        Z = self.scatter_agg(Y, sparse_graph.idxs[1,:], dim=0) # (2|E|, M_width) -> (|V|, M_width)\n",
    "        return self.U.forward(torch.cat((H,Z), dim=1)) # (|V|, H_width + M_width) -> (|V|, out_features)\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, Xv_width, Xe_width):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "        # First layer, (input dimension must match the initial dimension)\n",
    "        self.layers.append(GNN_layer(in_features=Xv_width, out_features=2, Xe_width=Xe_width, scatter_func='sum', U_depth=2, M_depth=2, M_width=2))\n",
    "        \n",
    "        # TODO: Add more layers (and actually figure out what needs to be done here)\n",
    "        self.layers.append(GNN_layer(in_features=2, out_features=2, Xe_width=Xe_width, scatter_func='sum', U_depth=2, M_depth=2, M_width=2))\n",
    "\n",
    "    def forward(self, sparse_graph):\n",
    "        # Initial Hidden node layers\n",
    "        H = sparse_graph.Xv\n",
    "\n",
    "        # Reshape if neccessary\n",
    "        if len(H.shape)==1:\n",
    "            H = H.reshape((-1,1))\n",
    "\n",
    "        # Reshape Edge feature matrix if neccessarry\n",
    "        if len(sparse_graph.Xe.shape)==1:\n",
    "            sparse_graph.Xe = sparse_graph.Xe.reshape((-1,1))\n",
    "            import warnings\n",
    "            warnings.warn(\"Needed to reshape Xe!!\")\n",
    "\n",
    "        # Pass \n",
    "        for layer in self.layers:\n",
    "            H = layer.forward(H, sparse_graph)\n",
    "        return H        \n",
    "\n",
    "\n",
    "gnn = GNN(Xv_width=1, Xe_width=1)\n",
    "foo = gnn.forward(sgl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(data)\n",
    "gnn = GNN(1,1)\n",
    "optimizer = optim.Adam(model.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_width = 3\n",
    "sg = sgl[0]\n",
    "\n",
    "# Determined\n",
    "in_features = 1#sg.Xv.shape[1]\n",
    "Xe_width = 1# sg.Xv.shape[1]\n",
    "H0 = sg.Xv\n",
    "H0 = H0.reshape(-1,1)\n",
    "\n",
    "# Pick and choose\n",
    "out_features = 2\n",
    "M_width = 2\n",
    "M_depth = 1\n",
    "U_depth = 1\n",
    "\n",
    "gnnl = GNN_layer(in_features, out_features, U_depth, M_depth, M_width, Xe_width)\n",
    "gnnl.forward(H0, sg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class GNN_layersss(torch.nn.Module):\n",
    "    def __init__(self, H_width=2, M_width=2, Xe_width=1):\n",
    "        super(GNN_layer, self).__init__()\n",
    "\n",
    "        self.H_width = H_width\n",
    "        self.M_width = M_width\n",
    "        import torch_scatter\n",
    "\n",
    "        self.scatter_agg = torch_scatter.scatter_add\n",
    "\n",
    "        self.M = SLP(H_width + Xe_width, 1)\n",
    "        self.U = SLP(H_width + M_width, H_width)\n",
    "\n",
    "    def forward(self, H, sparse_graph):\n",
    "        Y = M.forward(torch.cat(H[idxs[0,:]], Xe), dim=1) # (2|E|, H_width + Xe_width) -> (2|E|, M_width)\n",
    "        Z = self.scatter_agg(Y, idxs[1,:0], dim=0) # (2|E|, M_width) -> (|V|, M_width)\n",
    "        return U.forward(torch.cat((H,Z)), dim=1) # (|V|, H_width + M_width) -> (|V|, H_width)\n",
    "\n",
    "\n",
    "\n",
    "H_width = 3\n",
    "sg = sgl[0]\n",
    "\n",
    "H = torch.ones((sg.Xv.shape[0], H_width))\n",
    "\n",
    "gnn = GNN_layer(H_width, 2, sg.Xv.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.reshape((-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape # ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [59], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray([\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      3\u001b[0m M \u001b[39m=\u001b[39m SLP(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m M\u001b[39m.\u001b[39mforward(x\u001b[39m.\u001b[39;49mtranspose())\n",
      "\u001b[1;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "#x = torch.ones(shape=(2,1), dtype=np.float32).reshape(-1,1)\n",
    "x = torch.tensor(np.array([2,1]).reshape(-1,1), dtype=torch.float32)\n",
    "M = SLP(2,1)\n",
    "M.forward(x.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2,1]).reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = torch.from_numpy(np.array([1,1]).transpose().reshape(-1,1))\n",
    "sg = sgl[0]\n",
    "num_nodes = sg.Xv.shape[0]\n",
    "H = torch.ones((num_nodes))\n",
    "\n",
    "U = SLP(2,1)\n",
    "X = torch.transpose(torch.stack([H[sg.idxs[0,:]], sg.Xe]),0,1)\n",
    "Y = U.forward(X)\n",
    "Y.shape\n",
    "Y = torch.ones(Y.shape)\n",
    "\n",
    "Z = torch.zeros((2*num_nodes, 1), dtype=torch.float32)\n",
    "Z = Z.scatter_add_(dim=0, index= sg.idxs[1,:].reshape(-1,1), src=Y)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.7'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sg\u001b[39m.\u001b[39;49midxs[\u001b[39m2\u001b[39;49m,:]\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "sg.idxs[2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.idxs[1,:].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'scatter' for 'torch._C._TensorBase' objects doesn't apply to a 'int' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mTensor\u001b[39m.\u001b[39;49mscatter(\u001b[39m0\u001b[39;49m, sg\u001b[39m.\u001b[39;49midxs[\u001b[39m1\u001b[39;49m,:], Y)\n",
      "\u001b[1;31mTypeError\u001b[0m: descriptor 'scatter' for 'torch._C._TensorBase' objects doesn't apply to a 'int' object"
     ]
    }
   ],
   "source": [
    "torch.Tensor.scatter(0, sg.idxs[1,:], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = torch.empty((16,1), dtype=torch.float32)\n",
    "#idxx = torch.from_numpy(np.array([0]*17+[1]*17).astype('int64').reshape(-1,1))\n",
    "idxx = (sg.idxs[1,:]).reshape(-1,1)\n",
    "\n",
    "Z = Z.scatter_add(dim=0, index=idxx, src=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxx = (sg.idxs[1,:]).reshape(-1,1)\n",
    "idxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxx = torch.from_numpy(np.array([0]*8+[1]*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('gll')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3325763147d7b6a719f3ec3969238f3ee9907e3239cd74fe71b5fc36bf844357"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
